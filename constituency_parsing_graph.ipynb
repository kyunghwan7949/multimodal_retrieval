{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!pip install git+https://github.com/plandes/self-attentive-parser -qqq\n",
    "!pip install nltk\n",
    "!pip uninstall protobuf\n",
    "!pip install protobuf==3.20.3\n",
    "!pip install benepar\n",
    "!pip install svgling\n",
    "!pip install networkx\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package benepar_en3 to /root/nltk_data...\n",
      "[nltk_data]   Package benepar_en3 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import benepar\n",
    "import spacy\n",
    "import networkx as nx\n",
    "import torch\n",
    "\n",
    "nltk.download('punkt')\n",
    "benepar.download('benepar_en3')\n",
    "parser = benepar.Parser(\"benepar_en3\")\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### option 1.하나씩 그래프를 만들 경우\n",
    "- Constituency parsing graph \n",
    "- 노드 : 문법 노드 + 단어노드\n",
    "- 엣지 : 노드 연결여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문법적 구조 노드 종류\n",
    "tag_list = ['CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNS', 'NNP', 'NNPS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', 'S', 'SBAR', 'SBARQ', 'SINV', 'SQ', 'ADJP', 'ADVP', 'CONJP', 'FRAG', 'INTJ', 'LST', 'NAC', 'NP', 'NX', 'PP', 'PRN', 'PRT', 'QP', 'RRC', 'UCP', 'VP', 'WHADJP', 'WHADVP', 'WHNP', 'WHPP', 'X', '.', ',', '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cs_graph(text):\n",
    "    graph = nx.Graph()\n",
    "    tree = parser.parse(text)\n",
    "\n",
    "    node_texts = [] # 노드           -> 자연어\n",
    "    edge_texts = [] # (노드, 노드)쌍  -> 자연어\n",
    "    edge_index = [] # edge index     ->  index\n",
    "    node_index = 0\n",
    "    first_ancestor_info = [] # (단어노드, 단어노드의 조상노드)쌍 -> 자연어\n",
    "    labels = []\n",
    "\n",
    "    \n",
    "    ########## Tree 구조 탐색 ###############\n",
    "    def traverse_tree(tree, ancestors=[]):\n",
    "        nonlocal node_index\n",
    "        src = re.sub(r'\\.\\d+(\\.\\d+)*', '', tree.label())\n",
    "        src_index = node_index\n",
    "        node_index += 1\n",
    "\n",
    "        if src not in graph:\n",
    "            graph.add_node(src)\n",
    "            node_texts.append(src)\n",
    "\n",
    "        for i, child in enumerate(tree):\n",
    "            if type(child) is nltk.Tree: # 구문노드\n",
    "                tgt = re.sub(r'\\.\\d+(\\.\\d+)*', '', child.label())\n",
    "                tgt_index = node_index\n",
    "                node_index += 1\n",
    "\n",
    "                graph.add_node(tgt)\n",
    "                node_texts.append(tgt)\n",
    "\n",
    "                graph.add_edge(src, tgt)\n",
    "                edge_texts.append((src, tgt))\n",
    "                # edge_index.append([src_index, tgt_index])\n",
    "\n",
    "                # 현재 노드를 조상 목록에 추가하고 하위 트리를 탐색\n",
    "                traverse_tree(child, ancestors + [src])\n",
    "                \n",
    "            else: # 단어노드\n",
    "                leaf = re.sub(r'\\.\\d+(\\.\\d+)*', '', child)\n",
    "                leaf_index = node_index\n",
    "                node_index += 1\n",
    "                \n",
    "                graph.add_node(leaf)\n",
    "                node_texts.append(leaf)\n",
    "\n",
    "                graph.add_edge(src, leaf)\n",
    "                edge_texts.append((src, leaf))\n",
    "                # edge_index.append([src_index, leaf_index])\n",
    "\n",
    "                # 첫 번째 조상 노드를 찾아 저장\n",
    "                if ancestors and leaf not in tag_list:\n",
    "                    first_ancestor_info.append((leaf, ancestors[-1]))  \n",
    "                    \n",
    "    traverse_tree(tree)\n",
    "    \n",
    "    ##################### edgeg index ##############################\n",
    "    \n",
    "    def edge_index_search(tree, parent_index=-1, counter=[0]):\n",
    "        current_index = counter[0]\n",
    "        labels.append(tree.label() if type(tree) == nltk.tree.Tree else tree)\n",
    "        counter[0] += 1\n",
    "        if type(tree) == nltk.tree.Tree:\n",
    "            for subtree in tree:\n",
    "                edge_index.append([current_index, counter[0]])\n",
    "                edge_index.append([counter[0], current_index])\n",
    "                edge_index_search(subtree, counter[0], counter)\n",
    "            # total_edge_index.append(edge_index)\n",
    "    \n",
    "    edge_index_search(tree)\n",
    "\n",
    "    graph_data = {\n",
    "        'edge_index': torch.tensor(edge_index).T,\n",
    "        'node_tokens' : node_texts,\n",
    "        'edge_tokens' : edge_texts,\n",
    "        'first_ancestor_info': first_ancestor_info,\n",
    "    }\n",
    "    \n",
    "    return graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edge_index': tensor([[ 0,  1,  1,  2,  2,  3,  3,  4,  2,  5,  5,  6,  1,  7,  7,  8,  8,  9,\n",
       "           7, 10, 10, 11, 11, 12, 10, 13, 13, 14, 10, 15, 15, 16, 10, 17, 17, 18,\n",
       "           1, 19, 19, 20],\n",
       "         [ 1,  0,  2,  1,  3,  2,  4,  3,  5,  2,  6,  5,  7,  1,  8,  7,  9,  8,\n",
       "          10,  7, 11, 10, 12, 11, 13, 10, 14, 13, 15, 10, 16, 15, 17, 10, 18, 17,\n",
       "          19,  1, 20, 19]]),\n",
       " 'node_tokens': ['TOP',\n",
       "  'NP',\n",
       "  'NP',\n",
       "  'DT',\n",
       "  'a',\n",
       "  'NN',\n",
       "  'womna',\n",
       "  'VP',\n",
       "  'VBG',\n",
       "  'cutting',\n",
       "  'NP',\n",
       "  'DT',\n",
       "  'a',\n",
       "  'JJ',\n",
       "  'large',\n",
       "  'JJ',\n",
       "  'white',\n",
       "  'NN',\n",
       "  'cloth',\n",
       "  '.',\n",
       "  '.'],\n",
       " 'edge_tokens': [('TOP', 'NP'),\n",
       "  ('NP', 'NP'),\n",
       "  ('NP', 'DT'),\n",
       "  ('DT', 'a'),\n",
       "  ('NP', 'NN'),\n",
       "  ('NN', 'womna'),\n",
       "  ('NP', 'VP'),\n",
       "  ('VP', 'VBG'),\n",
       "  ('VBG', 'cutting'),\n",
       "  ('VP', 'NP'),\n",
       "  ('NP', 'DT'),\n",
       "  ('DT', 'a'),\n",
       "  ('NP', 'JJ'),\n",
       "  ('JJ', 'large'),\n",
       "  ('NP', 'JJ'),\n",
       "  ('JJ', 'white'),\n",
       "  ('NP', 'NN'),\n",
       "  ('NN', 'cloth'),\n",
       "  ('NP', '.'),\n",
       "  ('.', '.')],\n",
       " 'first_ancestor_info': [('a', 'NP'),\n",
       "  ('womna', 'NP'),\n",
       "  ('cutting', 'VP'),\n",
       "  ('a', 'NP'),\n",
       "  ('large', 'NP'),\n",
       "  ('white', 'NP'),\n",
       "  ('cloth', 'NP')]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_data = create_cs_graph('a womna cutting a large white cloth.')\n",
    "graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"264px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,384.0,264.0\" width=\"384px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">TOP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"22.9167%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"36.3636%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">a</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"18.1818%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"63.6364%\" x=\"36.3636%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">womna</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"68.1818%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"11.4583%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"70.8333%\" x=\"22.9167%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"26.4706%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBG</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cutting</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"13.2353%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"73.5294%\" x=\"26.4706%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"16%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">a</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"8%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"28%\" x=\"16%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">large</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"30%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"28%\" x=\"44%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">white</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"58%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"28%\" x=\"72%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cloth</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"86%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"63.2353%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"58.3333%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"6.25%\" x=\"93.75%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"96.875%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg>"
      ],
      "text/plain": [
       "Tree('TOP', [Tree('NP', [Tree('NP', [Tree('DT', ['a']), Tree('NN', ['womna'])]), Tree('VP', [Tree('VBG', ['cutting']), Tree('NP', [Tree('DT', ['a']), Tree('JJ', ['large']), Tree('JJ', ['white']), Tree('NN', ['cloth'])])]), Tree('.', ['.'])])])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 생성된 Constituency parsing graph 예시\n",
    "tree = parser.parse('a womna cutting a large white cloth.') # Input caption\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### option2. 데이터셋 한번에 생성하기 (1개 caption = 1개 그래프) : 데이터 경로및 환경 코드 수정 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "from typing import List\n",
    "\n",
    "from utils.iotools import read_json\n",
    "from utils.utils import pre_caption\n",
    "from utils.options import get_args\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from PIL import Image\n",
    "# import clip\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets.utils import download_url\n",
    "\n",
    "from .bases import BaseDataset\n",
    "from utils.simple_tokenizer import SimpleTokenizer\n",
    "from datasets.bases import tokenize\n",
    "\n",
    "import re\n",
    "\n",
    "import google.protobuf\n",
    "import nltk\n",
    "import benepar\n",
    "from nltk import Tree\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "benepar.download('benepar_en3')\n",
    "parser = benepar.Parser(\"benepar_en3\")\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "tag_list = ['CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNS', 'NNP', 'NNPS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', 'S', 'SBAR', 'SBARQ', 'SINV', 'SQ', 'ADJP', 'ADVP', 'CONJP', 'FRAG', 'INTJ', 'LST', 'NAC', 'NP', 'NX', 'PP', 'PRN', 'PRT', 'QP', 'RRC', 'UCP', 'VP', 'WHADJP', 'WHADVP', 'WHNP', 'WHPP', 'X', '.', ',', '?']\n",
    "\n",
    "# data preprocessing\n",
    "def pre_caption(caption, max_words=50):\n",
    "    caption = re.sub(\n",
    "        r\"([.!\\\"()*#:;~])\",       \n",
    "        ' ',\n",
    "        caption.lower(),\n",
    "    )\n",
    "    caption = re.sub(\n",
    "        r\"\\s{2,}\",\n",
    "        ' ',\n",
    "        caption,\n",
    "    )\n",
    "    caption = caption.rstrip('\\n') \n",
    "    caption = caption.strip(' ')\n",
    "\n",
    "    caption = re.sub(\n",
    "        r\"\\\"(.+?)\\\"\",\n",
    "        r\"\\1\",\n",
    "        caption,\n",
    "    )\n",
    "\n",
    "\n",
    "    caption_words = caption.split(' ')\n",
    "    if len(caption_words) > max_words:\n",
    "        caption = ' '.join(caption_words[:max_words])\n",
    "\n",
    "    return caption\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "class COCO_CS(Dataset):\n",
    "    \n",
    "    dataset_dir = 'COCO'\n",
    "    \n",
    "    def __init__(self, root=''):\n",
    "        super(COCO_CS, self).__init__()\n",
    "        \n",
    "        args = get_args()\n",
    "        self.dataset_dir = op.join(root, self.dataset_dir)\n",
    "        self.tokenizer = SimpleTokenizer()\n",
    "\n",
    "        self.coco_train_path = '/mount/MGM_train/data/COCO/coco_karpathy/train_caption_id.pk'\n",
    "        self.coco_val_path = '/mount/MGM_train/data/COCO/coco_karpathy/val_caption_id.json'\n",
    "\n",
    "        self.train, self.train_id_container = self._process_data(self.coco_train_path, training=True)\n",
    "        self.val, self.val_id_container = self._process_data(self.coco_val_path)\n",
    "\n",
    "        \n",
    "        self.train_graphs = self.generate_constituency_graph(self.train,training=\"train\")\n",
    "        self.val_graphs = self.generate_constituency_graph(self.val,training=\"val\")\n",
    "        \n",
    "\n",
    "    def _process_data(self, anno_path: str, training=False):\n",
    "        if training:\n",
    "            self.annotation = pickle.load(open(anno_path, 'rb'))\n",
    "            \n",
    "            self.img_ids = {}\n",
    "            n = 0\n",
    "            pid_container = set()\n",
    "            processed_data = []\n",
    "            \n",
    "            for ann in self.annotation:\n",
    "\n",
    "                image_id = ann['image'].split('/')[-1].strip('.jpg').split('_')[-1]\n",
    "                img_id = int(image_id)\n",
    "                \n",
    "                if img_id not in self.img_ids.keys():\n",
    "                    \n",
    "                    self.img_ids[img_id] = n\n",
    "\n",
    "                    pid_container.add(self.img_ids[img_id])\n",
    "                    n += 1\n",
    "\n",
    "                caption = pre_caption(ann['caption']) \n",
    "                instance_id = ann['instance_id']\n",
    "  \n",
    "                data = {\n",
    "                    'caption' : caption,\n",
    "                    'img_id' : image_id,\n",
    "                    'instance_id' : instance_id\n",
    "                }\n",
    "                processed_data.append((data))\n",
    "            for idx, pid in enumerate(pid_container):\n",
    "                    # check pid begin from 0 and no break\n",
    "                    assert idx == pid, f\"idx: {idx} and pid: {pid} are not match\"\n",
    "            return processed_data, pid_container\n",
    "        \n",
    "        else:\n",
    "            self.annotation = json.load(open(os.path.join(anno_path), 'r'))\n",
    "        \n",
    "            self.img_ids = {}\n",
    "            n = 0\n",
    "            pid_container = set()\n",
    "            processed_data = []\n",
    "            \n",
    "            for ann in self.annotation:\n",
    "                image_id = ann['image'].split('/')[-1].strip('.jpg').split('_')[-1]\n",
    "                img_id = int(image_id)\n",
    "                if img_id not in self.img_ids.keys():\n",
    "                    self.img_ids[img_id] = n\n",
    "                    pid_container.add(self.img_ids[img_id])\n",
    "                    n += 1\n",
    "                \n",
    "                caption = pre_caption(ann['caption'])\n",
    "                instance_id = ann['id']\n",
    "\n",
    "                data = {\n",
    "                    'caption' : caption,\n",
    "                    'img_id' : image_id,\n",
    "                    'instance_id' : instance_id\n",
    "                }\n",
    "                processed_data.append((data))\n",
    "            for idx, pid in enumerate(pid_container):\n",
    "                    # check pid begin from 0 and no break\n",
    "                    assert idx == pid, f\"idx: {idx} and pid: {pid} are not match\"\n",
    "            # print(len(pid_container))\n",
    "\n",
    "            return processed_data, pid_container\n",
    "        \n",
    "    def generate_constituency_graph(self, data, training=False):\n",
    "\n",
    "        if training == \"train\":\n",
    "            for i, caption in enumerate(data):\n",
    " \n",
    "                # Constituency Parsing Text Graph 생성\n",
    "                graph = nx.Graph()\n",
    "\n",
    "                node_texts = []\n",
    "                edge_texts = []\n",
    "                edge_index = []\n",
    "                node_index = 0\n",
    "                first_ancestor_info = []\n",
    "                labels = []\n",
    "\n",
    "                tree = parser.parse(f\"{caption['caption']}\")\n",
    "\n",
    "                def traverse_tree(tree, ancestors=[]):\n",
    "                    nonlocal node_index\n",
    "                    src = re.sub(r'\\.\\d+(\\.\\d+)*', '', tree.label())\n",
    "                    src_index = node_index\n",
    "                    node_index += 1\n",
    "\n",
    "                    if src not in graph:\n",
    "                        graph.add_node(src)\n",
    "                        node_texts.append(src)\n",
    "\n",
    "                    for i, child in enumerate(tree):\n",
    "                        if type(child) is nltk.Tree:\n",
    "                            tgt = re.sub(r'\\.\\d+(\\.\\d+)*', '', child.label())\n",
    "                            tgt_index = node_index\n",
    "                            node_index += 1\n",
    "\n",
    "                            graph.add_node(tgt)\n",
    "                            node_texts.append(tgt)\n",
    "\n",
    "                            graph.add_edge(src, tgt)\n",
    "                            edge_texts.append((src, tgt))\n",
    "                            # edge_index.append([src_index, tgt_index])\n",
    "\n",
    "                            # 현재 노드를 조상 목록에 추가하고 하위 트리를 탐색\n",
    "                            traverse_tree(child, ancestors + [src])\n",
    "                        else:\n",
    "                            leaf = re.sub(r'\\.\\d+(\\.\\d+)*', '', child)\n",
    "                            leaf_index = node_index\n",
    "                            node_index += 1\n",
    "                            \n",
    "                            graph.add_node(leaf)\n",
    "                            node_texts.append(leaf)\n",
    "\n",
    "                            graph.add_edge(src, leaf)\n",
    "                            edge_texts.append((src, leaf))\n",
    "                            # edge_index.append([src_index, leaf_index])\n",
    "                            \n",
    "                            # 첫 번째 조상 노드를 찾아 저장\n",
    "                            if ancestors and leaf not in tag_list:\n",
    "                                first_ancestor_info.append((leaf, ancestors[-1]))  # <-- 수정된 부분\n",
    "\n",
    "                traverse_tree(tree)\n",
    "                \n",
    "                ##################### edgeg index ##############################\n",
    "    \n",
    "                def edge_index_search(tree, parent_index=-1, counter=[0]):\n",
    "                    current_index = counter[0]\n",
    "                    labels.append(tree.label() if type(tree) == nltk.tree.Tree else tree)\n",
    "                    counter[0] += 1\n",
    "                    if type(tree) == nltk.tree.Tree:\n",
    "                        for subtree in tree:\n",
    "                            edge_index.append([current_index, counter[0]])\n",
    "                            edge_index.append([counter[0], current_index])\n",
    "                            edge_index_search(subtree, counter[0], counter)\n",
    "                \n",
    "                edge_index_search(tree)\n",
    "\n",
    "                graph_data = {\n",
    "                    'edge_index': torch.tensor(edge_index).T,\n",
    "                    'node_tokens' : node_texts,\n",
    "                    'edge_tokens' : edge_texts,\n",
    "                    'first_ancestor_info': first_ancestor_info,\n",
    "                }\n",
    "                \n",
    "                \n",
    "                graph_file_path = f'/data/data2/IRRA/COCO/cs_graph_train_v3/train_graph_{i}.pt'\n",
    "                torch.save(graph_data, graph_file_path)\n",
    "                print(f\"Creating Train Graph {i+1}/{len(data)}\")\n",
    "\n",
    "            return graph_data\n",
    "        \n",
    "        elif training == \"val\":\n",
    "            for i, caption in enumerate(data):\n",
    " \n",
    "                # Constituency Parsing Text Graph 생성\n",
    "                graph = nx.Graph()\n",
    "\n",
    "                node_texts = []\n",
    "                edge_texts = []\n",
    "                edge_index = []\n",
    "                node_index = 0\n",
    "                first_ancestor_info = []\n",
    "                labels = []\n",
    "\n",
    "                tree = parser.parse(f\"{caption['caption']}\")\n",
    "                \n",
    "                def traverse_tree(tree, ancestors=[]):\n",
    "                    nonlocal node_index\n",
    "                    src = re.sub(r'\\.\\d+(\\.\\d+)*', '', tree.label())\n",
    "                    src_index = node_index\n",
    "                    node_index += 1\n",
    "\n",
    "                    if src not in graph:\n",
    "                        graph.add_node(src)\n",
    "                        node_texts.append(src)\n",
    "\n",
    "                    for i, child in enumerate(tree):\n",
    "                        if type(child) is nltk.Tree:\n",
    "                            tgt = re.sub(r'\\.\\d+(\\.\\d+)*', '', child.label())\n",
    "                            tgt_index = node_index\n",
    "                            node_index += 1\n",
    "\n",
    "                            graph.add_node(tgt)\n",
    "                            node_texts.append(tgt)\n",
    "\n",
    "                            graph.add_edge(src, tgt)\n",
    "                            edge_texts.append((src, tgt))\n",
    "                            # edge_index.append([src_index, tgt_index])\n",
    "\n",
    "                            # 현재 노드를 조상 목록에 추가하고 하위 트리를 탐색\n",
    "                            traverse_tree(child, ancestors + [src])\n",
    "                        else:\n",
    "                            leaf = re.sub(r'\\.\\d+(\\.\\d+)*', '', child)\n",
    "                            leaf_index = node_index\n",
    "                            node_index += 1\n",
    "                            \n",
    "                            graph.add_node(leaf)\n",
    "                            node_texts.append(leaf)\n",
    "\n",
    "                            graph.add_edge(src, leaf)\n",
    "                            edge_texts.append((src, leaf))\n",
    "                            # edge_index.append([src_index, leaf_index])\n",
    "                            \n",
    "                            # 첫 번째 조상 노드를 찾아 저장\n",
    "                            if ancestors and leaf not in tag_list:\n",
    "                                first_ancestor_info.append((leaf, ancestors[-1]))  # <-- 수정된 부분\n",
    "\n",
    "                traverse_tree(tree)\n",
    "                \n",
    "                ##################### edgeg index ##############################\n",
    "    \n",
    "                def edge_index_search(tree, parent_index=-1, counter=[0]):\n",
    "                    current_index = counter[0]\n",
    "                    labels.append(tree.label() if type(tree) == nltk.tree.Tree else tree)\n",
    "                    counter[0] += 1\n",
    "                    if type(tree) == nltk.tree.Tree:\n",
    "                        for subtree in tree:\n",
    "                            edge_index.append([current_index, counter[0]])\n",
    "                            edge_index.append([counter[0], current_index])\n",
    "                            edge_index_search(subtree, counter[0], counter)\n",
    "                \n",
    "                edge_index_search(tree)\n",
    "\n",
    "                graph_data = {\n",
    "                    'edge_index': torch.tensor(edge_index).T,\n",
    "                    'node_tokens' : node_texts,\n",
    "                    'edge_tokens' : edge_texts,\n",
    "                    'first_ancestor_info': first_ancestor_info,\n",
    "                }\n",
    "\n",
    "                graph_file_path = f'/data/data2/IRRA/COCO/cs_graph_val_v3/val_graph_{i}.pt'\n",
    "                torch.save(graph_data, graph_file_path)\n",
    "                print(f\"Creating VAL Graph {i+1}/{len(data)}\")\n",
    "            \n",
    "                \n",
    "            return graph_data\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency Parsing Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "from typing import List\n",
    "\n",
    "from utils.iotools import read_json\n",
    "from utils.utils import pre_caption\n",
    "from utils.options import get_args\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets.utils import download_url\n",
    "\n",
    "from .bases import BaseDataset\n",
    "from utils.simple_tokenizer import SimpleTokenizer\n",
    "from datasets.bases import tokenize\n",
    "\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class COCO(Dataset):\n",
    "    \n",
    "    dataset_dir = 'COCO'\n",
    "    \n",
    "    def __init__(self, root='', prompt=''):\n",
    "        super(COCO, self).__init__()\n",
    "        \n",
    "        args = get_args()\n",
    "        self.dataset_dir = op.join(root, self.dataset_dir)\n",
    "        self.tokenizer = SimpleTokenizer()\n",
    "           \n",
    "        self.prompt = prompt\n",
    "        \n",
    "        self.train_filenames = '/mount/MGM_train/data/COCO/coco_karpathy/train_caption_id.pk'\n",
    "        self.val_filenames = '/mount/MGM_train/data/COCO/coco_karpathy/val_caption_id.json'\n",
    "        \n",
    "        \n",
    "        # self.train, self.train_id_container = self._process_data(self.train_filenames, training=True)\n",
    "        self.val, self.val_id_container = self._process_data(self.val_filenames)\n",
    "        \n",
    "        \n",
    "        self.train_graphs = self.generate_dependency_graph(self.train, training=\"train\")\n",
    "        # self.val_graphs = self.generate_dependency_graph(self.val, training=\"val\")\n",
    "        exit()\n",
    "\n",
    "\n",
    "    def _process_data(self, anno_path: str, training=False):\n",
    "        if training:\n",
    "            self.annotation = pickle.load(open(anno_path, 'rb'))\n",
    "            \n",
    "            self.img_ids = {}\n",
    "            n = 0\n",
    "            pid_container = set()\n",
    "            processed_data = []\n",
    "            \n",
    "            for ann in self.annotation:\n",
    "                # img_id = ann['image_id']\n",
    "                # pid_container.add(img_id)\n",
    "                image_id = ann['image'].split('/')[-1].strip('.jpg').split('_')[-1]\n",
    "                img_id = int(image_id)\n",
    "                \n",
    "                if img_id not in self.img_ids.keys():\n",
    "                    \n",
    "                    self.img_ids[img_id] = n\n",
    "                    pid_container.add(self.img_ids[img_id])\n",
    "                    n += 1\n",
    "\n",
    "                \n",
    "                caption = self.prompt + pre_caption(ann['caption']) \n",
    "                instance_id = ann['instance_id']\n",
    "\n",
    "                data = {\n",
    "                    'caption' : caption,\n",
    "                    'img_id' : image_id,\n",
    "                    'instance_id' : instance_id\n",
    "                }\n",
    "                processed_data.append((data))\n",
    "            for idx, pid in enumerate(pid_container):\n",
    "                    assert idx == pid, f\"idx: {idx} and pid: {pid} are not match\"\n",
    "            return processed_data, pid_container\n",
    "        \n",
    "        else:\n",
    "            self.annotation = json.load(open(os.path.join(anno_path), 'r'))\n",
    "        \n",
    "            self.img_ids = {}\n",
    "            n = 0\n",
    "            pid_container = set()\n",
    "            processed_data = []\n",
    "            \n",
    "            for ann in self.annotation:\n",
    "                image_id = ann['image'].split('/')[-1].strip('.jpg').split('_')[-1]\n",
    "                img_id = int(image_id)\n",
    "                if img_id not in self.img_ids.keys():\n",
    "                    self.img_ids[img_id] = n\n",
    "                    pid_container.add(self.img_ids[img_id])\n",
    "                    n += 1\n",
    "                \n",
    "                caption = self.prompt + pre_caption(ann['caption']) \n",
    "                instance_id = ann['id']\n",
    "                \n",
    "                data = {\n",
    "                    'caption' : caption,\n",
    "                    'img_id' : image_id,\n",
    "                    'instance_id' : instance_id\n",
    "                }\n",
    "                processed_data.append((data))\n",
    "            for idx, pid in enumerate(pid_container):\n",
    "                    assert idx == pid, f\"idx: {idx} and pid: {pid} are not match\"\n",
    "            print(len(pid_container))\n",
    "            \n",
    "            return processed_data, pid_container\n",
    "        \n",
    "    def generate_dependency_graph(self, data, training=False):\n",
    "        if training == \"train\":\n",
    "            for i, caption in enumerate(data):\n",
    "                doc = nlp(caption['caption'])\n",
    "                instance_id = caption['instance_id']\n",
    "                # Dependecny Parsing Text Graph 생성\n",
    "                G = nx.DiGraph()\n",
    "\n",
    "                edge_index = []\n",
    "                node_texts = []\n",
    "                edge_texts = []\n",
    "                triplets = []\n",
    "\n",
    "                for j, token in enumerate(doc):\n",
    "                    # print(len(doc))\n",
    "                    G.add_node(token.i, label=token.text)\n",
    "                    \n",
    "                    node_text = token.text\n",
    "                    node_texts.append(node_text)\n",
    "\n",
    "                for token in doc:\n",
    "                    # 두 노드 간 dependency가 있는 경우 엣지 연결\n",
    "                    if token.dep_ != 'ROOT':\n",
    "                        G.add_edge(token.head.i, token.i, label=token.dep_)\n",
    "                        G.add_edge(token.i, token.head.i, label=token.dep_)\n",
    "\n",
    "                        #엣지 CLIP 임베딩 생성\n",
    "                        triplet = f\"{token.head.text} - {token.dep_} - {token.text}\"\n",
    "                        edge_texts.append(token.dep_)\n",
    "                        triplets.append(triplet)\n",
    "                        \n",
    "                        # edge index 추가\n",
    "                        edge_index.append([token.head.i, token.i])\n",
    "                        edge_index.append([token.i, token.head.i])\n",
    "                                \n",
    "                graph_data = {\n",
    "                    'edge_index': torch.tensor(edge_index).T,\n",
    "                    'node_tokens' : node_texts,\n",
    "                    'edge_tokens' : edge_texts,\n",
    "                    'triplets' : triplets,\n",
    "                }\n",
    "\n",
    "                # graph_file_path = f'/mount/coco_irra/data/coco/train/train_graph_{instance_id}.pt'\n",
    "                graph_file_path = f'/data/data2/IRRA/COCO/tmp/dp_train/train_graph_{instance_id}.pt'\n",
    "                # torch.save(graph_data, graph_file_path)\n",
    "\n",
    "                print(f\"Creating Train Graph {j+1}/{len(doc)} of dataset {i+1}/{len(data)}\")\n",
    "            return graph_data\n",
    "        \n",
    "        elif training == \"val\":\n",
    "\n",
    "            for i, caption in enumerate(data):\n",
    "                doc = nlp(caption['caption'])\n",
    "                instance_id = caption['instance_id']\n",
    "\n",
    "                # Dependecny Parsing Text Graph 생성\n",
    "                G = nx.DiGraph()\n",
    "                \n",
    "                edge_index = []\n",
    "                node_texts = []\n",
    "                edge_texts = []\n",
    "                triplets = []\n",
    "\n",
    "                for j, token in enumerate(doc):\n",
    "                    # print(len(doc))\n",
    "                    G.add_node(token.i, label=token.text)\n",
    "                    \n",
    "                    node_text = token.text\n",
    "                    node_texts.append(node_text)\n",
    "\n",
    "                for token in doc:\n",
    "                    # 두 노드 간 dependency가 있는 경우 엣지 연결\n",
    "                    if token.dep_ != 'ROOT':\n",
    "                        G.add_edge(token.head.i, token.i, label=token.dep_)\n",
    "                        G.add_edge(token.i, token.head.i, label=token.dep_)\n",
    "\n",
    "                        triplet = f\"{token.head.text} - {token.dep_} - {token.text}\"\n",
    "                        edge_texts.append(token.dep_)\n",
    "                        triplets.append(triplet)\n",
    "\n",
    "                        # edge index 추가\n",
    "                        edge_index.append([token.head.i, token.i])\n",
    "                        edge_index.append([token.i, token.head.i])\n",
    "             \n",
    "                graph_data = {\n",
    "                    'edge_index': torch.tensor(edge_index).T,\n",
    "                    'node_tokens' : node_texts,\n",
    "                    'edge_tokens' : edge_texts,\n",
    "                    'triplets' : triplets,\n",
    "                }\n",
    "                \n",
    "                # graph_file_path = f'/mount/MGM_train/data/COCO/val/val_graph_{instance_id}.pt'\n",
    "                graph_file_path = f'/data/data2/IRRA/COCO/tmp/dp_val/val_graph_{instance_id}.pt'\n",
    "                # torch.save(graph_data, graph_file_path)\n",
    "                print(f\"Creating Validation Graph {j+1}/{len(doc)} of dataset {i+1}/{len(data)}\")\n",
    "            return graph_data\n",
    "\n",
    "        else:\n",
    "           pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
