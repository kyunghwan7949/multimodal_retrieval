{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705ec8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "    \n",
    "install('transformers==4.18.0')\n",
    "\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb745e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0370b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_name_2_coco_path(memory_graph, dialog): # 전체 memory_graph, dialog를 input으로 받아옴        \n",
    "    memory_image_path_dict = dict()\n",
    "    for d in dialog:\n",
    "        memory_graph_id = d['memory_graph_id']\n",
    "        cur_memory_graph = memory_graph[memory_graph_id]\n",
    "        for m in cur_memory_graph['memories']:\n",
    "            file_name = m['media'][0]['file_name']\n",
    "            memory_image_path_dict[file_name] = m['media'][0]['media_id'] # {####.jpg : coco_path} 형태       \n",
    "\n",
    "    return memory_image_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d41fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_id_day_dict(memory_graph): # memory_graph : key = memory_graph_id\n",
    "    memory_id_day_dict = dict()\n",
    "    for key in memory_graph.keys(): # memory graph id = key\n",
    "        cur_memory_graph = memory_graph[key]\n",
    "        for trip in cur_memory_graph['memory_groups']:\n",
    "            for day in trip['days']:\n",
    "                day_id = day['day_id'] # day_id = day\n",
    "                for event in day['events']:\n",
    "                    memories_idx_list = event['memories']\n",
    "                    for memory_idx in memories_idx_list:\n",
    "                        cur_memory = cur_memory_graph['memories'][memory_idx]\n",
    "                        cur_memory_id = cur_memory['memory_id']\n",
    "\n",
    "                        memory_id_day_dict[f'{key}_{cur_memory_id}'] = day_id\n",
    "                        \n",
    "    return memory_id_day_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ae2734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_id_trip_day_dict(memory_graph): # memory_graph : key = memory_graph_id\n",
    "    memory_id_trip_day_dict = dict()\n",
    "    for key in memory_graph.keys(): # memory graph id = key\n",
    "        cur_memory_graph = memory_graph[key]\n",
    "        for trip in cur_memory_graph['memory_groups']:\n",
    "            trip_id = trip['trip_id']\n",
    "            for day in trip['days']:\n",
    "                day_id = day['day_id'] # day_id = day\n",
    "                for event in day['events']:\n",
    "                    memories_idx_list = event['memories']\n",
    "                    for memory_idx in memories_idx_list:\n",
    "                        cur_memory = cur_memory_graph['memories'][memory_idx]\n",
    "                        cur_memory_id = cur_memory['memory_id']\n",
    "\n",
    "                        memory_id_trip_day_dict[f'{key}_{cur_memory_id}'] = f'{trip_id}_{day_id}'\n",
    "                        \n",
    "    return memory_id_trip_day_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d381792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_id_list(dialog_idx, turn_idx, dialog, memory_graph, memory_id_day_dict):\n",
    "    cur_memory_graph_id = dialog[dialog_idx]['memory_graph_id']\n",
    "    cur_memory_graph = memory_graph[cur_memory_graph_id]\n",
    "    cur_turn_memory_list = dialog[dialog_idx]['dialogue'][turn_idx]['system_transcript_annotated'][0]['act_attributes']['memories']\n",
    "    \n",
    "    if len(cur_turn_memory_list) > 0: # gt memory가 있을 경우에는 day 기준\n",
    "        cur_turn_day_list = [memory_id_day_dict[f'{cur_memory_graph_id}_{x}'] for x in cur_turn_memory_list]\n",
    "        cur_memory_graph_list = [k for k, v in memory_id_day_dict.items() if ((v <= max(cur_turn_day_list)) & (cur_memory_graph_id in k))]\n",
    "    else: # 아닐경우에는 모든 memory 가져옴\n",
    "        cur_memory_graph_list = [k for k, v in memory_id_day_dict.items() if (cur_memory_graph_id in k)]\n",
    "        \n",
    "    return cur_memory_graph_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc9ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attr_list(memory):\n",
    "    attr_list = []\n",
    "    \n",
    "    # memory_id\n",
    "    attr_list.append(f'memory_id_{memory[\"memory_id\"]}')\n",
    "    \n",
    "    # time\n",
    "    attr_list.append(memory['time'])\n",
    "    \n",
    "    # narrations\n",
    "    attr_list.append(memory['narrations'])\n",
    "    \n",
    "#     # media\n",
    "#     cur_media_name = memory['media'][0]['file_name']\n",
    "#     cur_media = file_name_2_coco_dict[cur_media_name]\n",
    "#     attr_list.append(cur_media) # media (jpg)\n",
    "    \n",
    "    # location flatten string\n",
    "    loc_dict = memory['location']['geo_tag']\n",
    "    cur_location = ' '.join([loc_dict['place'], loc_dict['place_type'], ' '.join(memory['location']['category']), loc_dict['city'], loc_dict['state'], loc_dict['country']])\n",
    "    attr_list.append(cur_location) \n",
    "    \n",
    "    # activity\n",
    "    attr_list.append(memory['activity'][0]['activity_name'])\n",
    "    \n",
    "    # participant\n",
    "    participant_list = memory['participant']\n",
    "    if len(participant_list) > 0:\n",
    "        cur_participant = [x['name'] for x in participant_list]\n",
    "        cur_participant = ' '.join([i for i in cur_participant if i is not None])\n",
    "        attr_list.append(cur_participant)\n",
    "    \n",
    "    # object\n",
    "    object_list = memory['objects']\n",
    "    if len(object_list) > 0:\n",
    "        cur_object = ' '.join(object_list)\n",
    "        attr_list.append(cur_object)\n",
    "        \n",
    "    # time_part\n",
    "    attr_list.append(memory['time_part'])\n",
    "    \n",
    "    return attr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49e947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_attr_list(memory_graph, graph_id, memory_id):\n",
    "    cur_memory_graph = memory_graph[graph_id]['memories']\n",
    "    for m in cur_memory_graph:\n",
    "        if str(m['memory_id']) == memory_id:\n",
    "            cur_memory = m\n",
    "            break\n",
    "     \n",
    "    attr_list = get_attr_list(cur_memory)\n",
    "\n",
    "    return attr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716eef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cos_similarity(question, mem_attr_list, tokenizer, model, option):\n",
    "    sim_list = []\n",
    "    \n",
    "    # question\n",
    "    enc_question = tokenizer(str(question), return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        out_question = model(**enc_question)\n",
    "    states_question = out_question.hidden_states[-1].squeeze()\n",
    "    avg_question = states_question.mean(axis = 0)\n",
    "    \n",
    "    enc_attr = tokenizer(mem_attr_list, return_tensors=\"pt\", padding = True)\n",
    "    with torch.no_grad():\n",
    "        out_attr = model(**enc_attr)\n",
    "    states_attr = out_attr.hidden_states[-1].squeeze()\n",
    "    avg_attr = states_attr.mean(axis = 0)\n",
    "\n",
    "    sim_list = torch.cosine_similarity(avg_question, avg_attr, dim = 0).tolist()\n",
    "    \n",
    "    if option == 'memory':\n",
    "        sim_list.sort(reverse = True)\n",
    "        sim_score = np.array(sim_list[:5]).mean()\n",
    "    elif option == 'attribute':\n",
    "        sim_score = sim_list\n",
    "    \n",
    "    return sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d254d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_sample(similarity_dict, option): # key = memory_id, value = similarity\n",
    "    prob_array = np.array(list(similarity_dict.values()))\n",
    "    normalized_prob_array = prob_array/sum(prob_array)\n",
    "    \n",
    "    if option == 'memory':\n",
    "        size = 4\n",
    "    elif option == 'attribute':\n",
    "        size = 32\n",
    "    return np.random.choice(list(similarity_dict.keys()), size = size, p = normalized_prob_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b454d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_option_1(dialog_idx, memory_graph, dialog): # turn 상관없이 dialog 전체에서 보는 graph에서 sampling\n",
    "    # memory_graph_id를 key값으로 사용하기 위해 변경\n",
    "    for i in memory_graph:\n",
    "        if i['memory_graph_id'] == dialog[dialog_idx]['memory_graph_id']:\n",
    "            cur_memory_graph = i\n",
    "            break\n",
    "            \n",
    "    num_memories = len(cur_memory_graph['memories'])    \n",
    "    memory_idx_list = np.random.randint(low = 0, high = num_memories, size = 4)\n",
    "    attr_sample = []\n",
    "    for memory_idx in memory_idx_list:\n",
    "        cur_memory = cur_memory_graph['memories'][memory_idx]\n",
    "        \n",
    "        attr_sample.append(get_attr_list(cur_memory))\n",
    "        \n",
    "    attr_sample = sum(attr_sample, [])\n",
    "    \n",
    "    return attr_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bfe752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_option_2(dialog_idx, turn_idx, memory_graph, dialog):\n",
    "    # 현재 dialog에 해당하는 memory graph만 사용\n",
    "    memory_graph_dict = dict()\n",
    "    for i in memory_graph:\n",
    "        if i['memory_graph_id'] == dialog[dialog_idx]['memory_graph_id']:\n",
    "            memory_graph_dict[i['memory_graph_id']] = i\n",
    "            break\n",
    "    memory_graph = memory_graph_dict\n",
    "            \n",
    "    # {memory id : day} 로 저장\n",
    "    memory_id_day_dict = get_memory_id_day_dict(memory_graph)\n",
    "    \n",
    "    # 특정 dialog - turn에서 보는 memory list\n",
    "    cur_memory_graph_list = get_memory_id_list(dialog_idx, turn_idx, dialog, memory_graph, memory_id_day_dict)\n",
    "    num_memories = len(cur_memory_graph_list)\n",
    "    memory_idx_list = np.random.randint(low = 0, high = num_memories, size = 4)\n",
    "    \n",
    "    attr_sample = []\n",
    "    \n",
    "    for memory in cur_memory_graph_list:\n",
    "        # memory 내의 attribute list로 반환\n",
    "        graph_id = memory.split('_')[0]\n",
    "        memory_id = memory.split('_')[1]\n",
    "        \n",
    "        # memory내의 attribute들을 list로 반환\n",
    "        mem_attr_list = get_memory_attr_list(memory_graph, graph_id, memory_id)\n",
    "        attr_sample.append(mem_attr_list)\n",
    "        \n",
    "    attr_sample = sum(attr_sample, [])\n",
    "    \n",
    "    return attr_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a781648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_option_3(dialog_idx, turn_idx, memory_graph, dialog, tokenizer, model): # 1100개 memory sample, dialog 파일\n",
    "    option = 'memory'\n",
    "    # 현재 dialog에 해당하는 memory graph만 사용\n",
    "    memory_graph_dict = dict()\n",
    "    for i in memory_graph:\n",
    "        if i['memory_graph_id'] == dialog[dialog_idx]['memory_graph_id']:\n",
    "            memory_graph_dict[i['memory_graph_id']] = i\n",
    "            break\n",
    "    memory_graph = memory_graph_dict\n",
    "    \n",
    "    # {memory id : day} 로 저장\n",
    "    memory_id_day_dict = get_memory_id_day_dict(memory_graph)\n",
    "    \n",
    "    # 특정 dialog - turn에서 보는 memory list\n",
    "    cur_memory_graph_list = get_memory_id_list(dialog_idx, turn_idx, dialog, memory_graph, memory_id_day_dict)\n",
    "\n",
    "    # 현재 turn의 question 가져오기\n",
    "    question = dialog[dialog_idx]['dialogue'][turn_idx]['transcript_annotated'][0]['uttr']\n",
    "    \n",
    "    # walk 돌릴 확률 저장 {memory_id : similarity}\n",
    "    prob_dict = dict()\n",
    "    # attribute 저장 {memory_id : attribute}\n",
    "    attr_dict = dict()\n",
    "    memory_list = []\n",
    "    sim_list = []\n",
    "\n",
    "    # memory별로 for문 돌면서 similarity 계산\n",
    "    for memory in cur_memory_graph_list:\n",
    "\n",
    "        graph_id = memory.split('_')[0]\n",
    "        memory_id = memory.split('_')[1]\n",
    "\n",
    "        # memory내의 attribute들을 list로 반환\n",
    "        mem_attr_list = get_memory_attr_list(memory_graph, graph_id, memory_id)\n",
    "        attr_dict[memory] = mem_attr_list\n",
    "\n",
    "    # memory와 question similarity 계산\n",
    "    for memory in attr_dict.keys():\n",
    "        mem_attr_list = attr_dict[memory]\n",
    "        sim = calc_cos_similarity(question, mem_attr_list, tokenizer, model, option)\n",
    "        memory_list.append(memory)\n",
    "        sim_list.append(sim)\n",
    "    \n",
    "    prob_list = softmax(sim_list)\n",
    "    for k, v in zip(memory_list, prob_list):\n",
    "        prob_dict[k] = v\n",
    "        \n",
    "    # sampling\n",
    "    memory_sample = get_random_sample(prob_dict, option)\n",
    "    attr_sample = [attr_dict[key] for key in memory_sample]\n",
    "    \n",
    "    # flatten\n",
    "    attr_sample = sum(attr_sample, [])\n",
    "    \n",
    "    return attr_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b9613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_option_4(dialog_idx, turn_idx, memory_graph, dialog, tokenizer, model):\n",
    "    option = 'attribute'\n",
    "    # 현재 dialog에 해당하는 memory graph만 사용\n",
    "    memory_graph_dict = dict()\n",
    "    for i in memory_graph:\n",
    "        if i['memory_graph_id'] == dialog[dialog_idx]['memory_graph_id']:\n",
    "            memory_graph_dict[i['memory_graph_id']] = i\n",
    "            break\n",
    "    memory_graph = memory_graph_dict\n",
    "    \n",
    "    # {memory id : day} 로 저장\n",
    "    memory_id_day_dict = get_memory_id_day_dict(memory_graph)\n",
    "    \n",
    "    # 특정 dialog - turn에서 보는 memory list\n",
    "    cur_memory_graph_list = get_memory_id_list(dialog_idx, turn_idx, dialog, memory_graph, memory_id_day_dict)\n",
    "\n",
    "    # 현재 turn의 question 가져오기\n",
    "    question = dialog[dialog_idx]['dialogue'][turn_idx]['transcript_annotated'][0]['uttr']\n",
    "    \n",
    "    # walk 돌릴 확률 저장 {attr : similarity}\n",
    "    prob_dict = dict()\n",
    "    attr_list = []\n",
    "    sim_list = []\n",
    "\n",
    "    # memory별로 for문 돌면서 similarity 계산\n",
    "    for memory in cur_memory_graph_list:\n",
    "\n",
    "        graph_id = memory.split('_')[0]\n",
    "        memory_id = memory.split('_')[1]\n",
    "\n",
    "        # memory내의 attribute들을 list로 반환\n",
    "        mem_attr_list = get_memory_attr_list(memory_graph, graph_id, memory_id)\n",
    "        attr_list.append(mem_attr_list)\n",
    "        \n",
    "    # attribute와 question similarity 계산\n",
    "    mem_attr_list_flatten = sum(attr_list, [])\n",
    "    sim_list = calc_cos_similarity(question, mem_attr_list_flatten, tokenizer, model, option)\n",
    "    prob_list = softmax(sim_list)\n",
    "        \n",
    "    attr_list = sum(attr_list, [])\n",
    "        \n",
    "    for k, v in zip(attr_list, prob_list):\n",
    "        prob_dict[k] = v\n",
    "        \n",
    "    # sampling\n",
    "    attr_sample = list(get_random_sample(prob_dict, option))\n",
    "    \n",
    "    return attr_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d24adfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_option_6(dialog_idx, turn_idx, memory_graph, dialog, tokenizer, model):\n",
    "    option = 'memory'\n",
    "    memory_graph_id = dialog[dialog_idx]['memory_graph_id']\n",
    "    \n",
    "    # 현재 dialog에 해당하는 memory graph만 사용\n",
    "    memory_graph_dict = dict()\n",
    "    for i in memory_graph:\n",
    "        if i['memory_graph_id'] == memory_graph_id:\n",
    "            memory_graph_dict[i['memory_graph_id']] = i\n",
    "            break\n",
    "    memory_graph = memory_graph_dict\n",
    "\n",
    "    # {memory id : trip_day} 으로 저장\n",
    "    memory_id_trip_day_dict = get_memory_id_trip_day_dict(memory_graph)\n",
    "\n",
    "    # 현재 turn의 question 가져오기\n",
    "    question = dialog[dialog_idx]['dialogue'][turn_idx]['transcript_annotated'][0]['uttr']\n",
    "\n",
    "    t_d_sim_dict = dict()\n",
    "\n",
    "    # trip-day 선택\n",
    "    t_d_set = set([x for x in list(memory_id_trip_day_dict.values())])\n",
    "\n",
    "    for t_d in t_d_set:\n",
    "        attr_dict = dict()\n",
    "        sim_list = []\n",
    "\n",
    "        cur_memory_list = [k for k, v in memory_id_trip_day_dict.items() if (t_d == v)]\n",
    "\n",
    "        # memory별로 for문 돌면서 similarity 계산\n",
    "        for memory in cur_memory_list:\n",
    "\n",
    "            graph_id = memory.split('_')[0]\n",
    "            memory_id = memory.split('_')[1]\n",
    "\n",
    "            # memory내의 attribute들을 list로 반환\n",
    "            mem_attr_list = get_memory_attr_list(memory_graph, graph_id, memory_id)\n",
    "            attr_dict[memory] = mem_attr_list\n",
    "\n",
    "        # memory와 question similarity 계산\n",
    "        for memory in attr_dict.keys():\n",
    "            mem_attr_list = attr_dict[memory]\n",
    "            sim = calc_cos_similarity(question, mem_attr_list, tokenizer, model, option)\n",
    "            sim_list.append(sim)\n",
    "\n",
    "        t_d_sim_dict[t_d] = np.mean(sim_list)\n",
    "\n",
    "    max_similarity = np.max(list(t_d_sim_dict.values()))\n",
    "    cur_t_d = next(k for k, v in t_d_sim_dict.items() if v == max_similarity)\n",
    "    cur_mem_list = [k for k, v in memory_id_trip_day_dict.items() if (cur_t_d == v)]\n",
    "\n",
    "    # memory내의 attribute들을 list로 반환\n",
    "    attr_sample = []\n",
    "    memory_id_list = [x.split('_')[1] for x in cur_memory_list]\n",
    "    for m in memory_id_list:\n",
    "        attr_sample.append(get_memory_attr_list(memory_graph, memory_graph_id, m))\n",
    "\n",
    "    attr_sample = sum(attr_sample, [])\n",
    "\n",
    "    return attr_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_data_dir = '/home/work/.data/comet_memory_dialog/data' # dialog, memory graph 있는 위치\n",
    "\n",
    "memory_graph = json.load(open(\n",
    "    os.path.join(comet_data_dir, 'mscoco_memory_graphs_1k.json')\n",
    ")) + json.load(open(\n",
    "    os.path.join(comet_data_dir, 'memory_may21_v1_100graphs.json')\n",
    "))\n",
    "\n",
    "split = 'train' # train/test/val\n",
    "dialog = json.load(open(\n",
    "    os.path.join(comet_data_dir, f'mem_dials_{split}.json')\n",
    "))['dialogue_data']\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\", output_hidden_states = True).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f69894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f0a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for d_idx, d in enumerate(dialog[:1]):\n",
    "    for t_idx, t in enumerate(d['dialogue']):\n",
    "        get_memory_option_1(0, memory_graph, dialog)\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09d5665",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for dialog_idx, d in enumerate(dialog[:1]):\n",
    "    for turn_idx, t in enumerate(d['dialogue']):\n",
    "        get_memory_option_2(dialog_idx, turn_idx, memory_graph, dialog)\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aff3290",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for dialog_idx, d in enumerate(dialog[:1]):\n",
    "    for turn_idx, t in enumerate(d['dialogue']):\n",
    "        get_memory_option_3(dialog_idx, turn_idx, memory_graph, dialog, tokenizer, model)\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b004b199",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for dialog_idx, d in enumerate(dialog[:1]):\n",
    "    for turn_idx, t in enumerate(d['dialogue']):\n",
    "        get_memory_option_4(dialog_idx, turn_idx, memory_graph, dialog, tokenizer, model)\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a1918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for dialog_idx, d in enumerate(dialog[:1]):\n",
    "    for turn_idx, t in enumerate(d['dialogue']):\n",
    "        get_memory_option_6(dialog_idx, turn_idx, memory_graph, dialog, tokenizer, model)\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adf2dff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 용량: 3220 바이트\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = '/data/data2/khahn/comet_memory_dialog_former/update_memory_graph/created_memory/train/option_3/option_3_116.pkl'  # pickle 파일의 경로\n",
    "\n",
    "# 파일의 크기를 바이트 단위로 얻기\n",
    "file_size = os.path.getsize(file_path)\n",
    "\n",
    "print(f\"파일 용량: {file_size} 바이트\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e9e18ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 용량: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = '/data/data2/khahn/comet_memory_dialog_former/update_memory_graph/created_memory/train/option_3/option_3_116.pkl'  # pickle 파일의 경로\n",
    "\n",
    "# 파일의 크기를 바이트 단위로 얻기\n",
    "file_size = os.path.getsize(file_path)\n",
    "\n",
    "# 바이트를 기가바이트로 환산\n",
    "file_size_gb = file_size / (1024 ** 3)\n",
    "\n",
    "print(f\"파일 용량: {file_size_gb:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc22c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "PyTorch 1.14 (NGC 22.12/Python 3.8) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
